{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15976a3-c02c-4c50-b35a-134e063859d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'  # O '0,1' para usar múltiples GPUs\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import fnmatch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636d6ade-9e77-4846-99a5-25c76baeac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "#!wget https://www.openslr.org/resources/17/musan.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061c43b8-4266-428f-ae48-bf5e97a2056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xvf dev-clean.tar.gz\n",
    "#!tar -xvf musan.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4853777a-b991-4efd-906c-4f1edebf6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = lines[11:]\n",
    "    lines = [line.replace('|CBW|', 'CBW').strip() for line in lines]\n",
    "    lines[0] = lines[0].replace(';', '')\n",
    "    cleaned_text = '\\n'.join(lines)\n",
    "    df = pd.read_csv(StringIO(cleaned_text), sep='|', engine='python')\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c8b4dc-d34a-4161-a7c4-5d8876080dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"LibriSpeech/\"\n",
    "speakers_txt = base_path + \"SPEAKERS.TXT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1dd6f4c-4eac-4155-bdc8-6009a5493191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_with_extensions(root_dir, extensions):\n",
    "    matched_files = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        for pattern in extensions:\n",
    "            for filename in fnmatch.filter(files, pattern):\n",
    "                if not filename.startswith('.'):\n",
    "                    matched_files.append(os.path.join(root, filename))\n",
    "\n",
    "    return matched_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add11b79-c4f1-4894-86e5-3caf2b76c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2703\n"
     ]
    }
   ],
   "source": [
    "files_list = list(find_files_with_extensions(\"LibriSpeech/\",[\"*.flac\"]))\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b62e97-8df6-40ca-8025-e51888347aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_to_df(files_list):\n",
    "    df = pd.DataFrame(files_list, columns=['Path'])\n",
    "    df_expanded = df['Path'].str.split('/', expand=True)\n",
    "    df_expanded.columns = [f'Folder_{i}' for i in range(df_expanded.shape[1])]\n",
    "    df_expanded['Full_Path'] = df.apply(lambda row: '/'.join(row.astype(str)), axis=1)\n",
    "    return df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b238c597-6485-48b7-840c-4ffd4562c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_files = ls_to_df(files_list)\n",
    "speakers_info = preprocess_file(speakers_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa52225-0364-4652-a716-1f924eec7ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.03</td>\n",
       "      <td>Kristin LeMoine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.11</td>\n",
       "      <td>Alys AtteWater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.04</td>\n",
       "      <td>Gord Mackenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-100</td>\n",
       "      <td>25.19</td>\n",
       "      <td>Kara Shallenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>train-other-500</td>\n",
       "      <td>30.07</td>\n",
       "      <td>Gesine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>8975</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-100</td>\n",
       "      <td>25.11</td>\n",
       "      <td>Daisy Flaim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>9000</td>\n",
       "      <td>M</td>\n",
       "      <td>train-other-500</td>\n",
       "      <td>27.26</td>\n",
       "      <td>Ramon Escamilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>9022</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.17</td>\n",
       "      <td>Claire M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>9023</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.19</td>\n",
       "      <td>P. J. Morgan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>9026</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>21.75</td>\n",
       "      <td>Tammy Porter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID SEX           SUBSET  MINUTES              NAME\n",
       "0       14   F  train-clean-360    25.03   Kristin LeMoine\n",
       "1       16   F  train-clean-360    25.11    Alys AtteWater\n",
       "2       17   M  train-clean-360    25.04    Gord Mackenzie\n",
       "3       19   F  train-clean-100    25.19  Kara Shallenberg\n",
       "4       20   F  train-other-500    30.07            Gesine\n",
       "...    ...  ..              ...      ...               ...\n",
       "2479  8975   F  train-clean-100    25.11       Daisy Flaim\n",
       "2480  9000   M  train-other-500    27.26   Ramon Escamilla\n",
       "2481  9022   F  train-clean-360    25.17          Claire M\n",
       "2482  9023   F  train-clean-360    25.19      P. J. Morgan\n",
       "2483  9026   F  train-clean-360    21.75      Tammy Porter\n",
       "\n",
       "[2484 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d82a610e-80d8-4842-ac13-6422db3b9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_info[\"SECONDS\"] = speakers_info[\"MINUTES\"] * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925c85ab-befc-4478-bf94-16fce9441682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SECONDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.03</td>\n",
       "      <td>Kristin LeMoine</td>\n",
       "      <td>1501.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.11</td>\n",
       "      <td>Alys AtteWater</td>\n",
       "      <td>1506.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.04</td>\n",
       "      <td>Gord Mackenzie</td>\n",
       "      <td>1502.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-100</td>\n",
       "      <td>25.19</td>\n",
       "      <td>Kara Shallenberg</td>\n",
       "      <td>1511.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>train-other-500</td>\n",
       "      <td>30.07</td>\n",
       "      <td>Gesine</td>\n",
       "      <td>1804.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>8975</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-100</td>\n",
       "      <td>25.11</td>\n",
       "      <td>Daisy Flaim</td>\n",
       "      <td>1506.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>9000</td>\n",
       "      <td>M</td>\n",
       "      <td>train-other-500</td>\n",
       "      <td>27.26</td>\n",
       "      <td>Ramon Escamilla</td>\n",
       "      <td>1635.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>9022</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.17</td>\n",
       "      <td>Claire M</td>\n",
       "      <td>1510.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>9023</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>25.19</td>\n",
       "      <td>P. J. Morgan</td>\n",
       "      <td>1511.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>9026</td>\n",
       "      <td>F</td>\n",
       "      <td>train-clean-360</td>\n",
       "      <td>21.75</td>\n",
       "      <td>Tammy Porter</td>\n",
       "      <td>1305.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID SEX           SUBSET  MINUTES              NAME  SECONDS\n",
       "0       14   F  train-clean-360    25.03   Kristin LeMoine   1501.8\n",
       "1       16   F  train-clean-360    25.11    Alys AtteWater   1506.6\n",
       "2       17   M  train-clean-360    25.04    Gord Mackenzie   1502.4\n",
       "3       19   F  train-clean-100    25.19  Kara Shallenberg   1511.4\n",
       "4       20   F  train-other-500    30.07            Gesine   1804.2\n",
       "...    ...  ..              ...      ...               ...      ...\n",
       "2479  8975   F  train-clean-100    25.11       Daisy Flaim   1506.6\n",
       "2480  9000   M  train-other-500    27.26   Ramon Escamilla   1635.6\n",
       "2481  9022   F  train-clean-360    25.17          Claire M   1510.2\n",
       "2482  9023   F  train-clean-360    25.19      P. J. Morgan   1511.4\n",
       "2483  9026   F  train-clean-360    21.75      Tammy Porter   1305.0\n",
       "\n",
       "[2484 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22c4735-f357-47a1-a77e-9effca4fbeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX\n",
       "M    1283\n",
       "F    1201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_info[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de47d0ae-6e8e-485b-b513-a38e591d1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_info[\"ID\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259beaf5-9fe7-4001-91d9-24cc27c05a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder_0</th>\n",
       "      <th>Folder_1</th>\n",
       "      <th>Folder_2</th>\n",
       "      <th>Folder_3</th>\n",
       "      <th>Folder_4</th>\n",
       "      <th>Full_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0010.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0011.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0008.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0012.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0009.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0031.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0006.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0017.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0032.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>LibriSpeech</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0049.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2703 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Folder_0   Folder_1 Folder_2 Folder_3               Folder_4  \\\n",
       "0     LibriSpeech  dev-clean     8842   302196  8842-302196-0010.flac   \n",
       "1     LibriSpeech  dev-clean     8842   302196  8842-302196-0011.flac   \n",
       "2     LibriSpeech  dev-clean     8842   302196  8842-302196-0008.flac   \n",
       "3     LibriSpeech  dev-clean     8842   302196  8842-302196-0012.flac   \n",
       "4     LibriSpeech  dev-clean     8842   302196  8842-302196-0009.flac   \n",
       "...           ...        ...      ...      ...                    ...   \n",
       "2698  LibriSpeech  dev-clean     2078   142845  2078-142845-0031.flac   \n",
       "2699  LibriSpeech  dev-clean     2078   142845  2078-142845-0006.flac   \n",
       "2700  LibriSpeech  dev-clean     2078   142845  2078-142845-0017.flac   \n",
       "2701  LibriSpeech  dev-clean     2078   142845  2078-142845-0032.flac   \n",
       "2702  LibriSpeech  dev-clean     2078   142845  2078-142845-0049.flac   \n",
       "\n",
       "                                              Full_Path  \n",
       "0     LibriSpeech/dev-clean/8842/302196/8842-302196-...  \n",
       "1     LibriSpeech/dev-clean/8842/302196/8842-302196-...  \n",
       "2     LibriSpeech/dev-clean/8842/302196/8842-302196-...  \n",
       "3     LibriSpeech/dev-clean/8842/302196/8842-302196-...  \n",
       "4     LibriSpeech/dev-clean/8842/302196/8842-302196-...  \n",
       "...                                                 ...  \n",
       "2698  LibriSpeech/dev-clean/2078/142845/2078-142845-...  \n",
       "2699  LibriSpeech/dev-clean/2078/142845/2078-142845-...  \n",
       "2700  LibriSpeech/dev-clean/2078/142845/2078-142845-...  \n",
       "2701  LibriSpeech/dev-clean/2078/142845/2078-142845-...  \n",
       "2702  LibriSpeech/dev-clean/2078/142845/2078-142845-...  \n",
       "\n",
       "[2703 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede106e4-438b-4cd4-adf2-602ded02775f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder_2</th>\n",
       "      <th>Folder_3</th>\n",
       "      <th>Folder_4</th>\n",
       "      <th>Full_Path</th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SECONDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0010.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0011.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0008.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0012.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0009.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0031.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0006.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0017.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0032.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0049.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2703 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Folder_2  Folder_3               Folder_4  \\\n",
       "0         8842    302196  8842-302196-0010.flac   \n",
       "1         8842    302196  8842-302196-0011.flac   \n",
       "2         8842    302196  8842-302196-0008.flac   \n",
       "3         8842    302196  8842-302196-0012.flac   \n",
       "4         8842    302196  8842-302196-0009.flac   \n",
       "...        ...       ...                    ...   \n",
       "2698      2078    142845  2078-142845-0031.flac   \n",
       "2699      2078    142845  2078-142845-0006.flac   \n",
       "2700      2078    142845  2078-142845-0017.flac   \n",
       "2701      2078    142845  2078-142845-0032.flac   \n",
       "2702      2078    142845  2078-142845-0049.flac   \n",
       "\n",
       "                                              Full_Path    ID SEX     SUBSET  \\\n",
       "0     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "1     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "2     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "3     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "4     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "...                                                 ...   ...  ..        ...   \n",
       "2698  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2699  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2700  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2701  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2702  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "\n",
       "      MINUTES         NAME  SECONDS  \n",
       "0        8.10       Mary J    486.0  \n",
       "1        8.10       Mary J    486.0  \n",
       "2        8.10       Mary J    486.0  \n",
       "3        8.10       Mary J    486.0  \n",
       "4        8.10       Mary J    486.0  \n",
       "...       ...          ...      ...  \n",
       "2698     8.03  Kathy Caver    481.8  \n",
       "2699     8.03  Kathy Caver    481.8  \n",
       "2700     8.03  Kathy Caver    481.8  \n",
       "2701     8.03  Kathy Caver    481.8  \n",
       "2702     8.03  Kathy Caver    481.8  \n",
       "\n",
       "[2703 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_files[\"Folder_2\"] = df_list_files[\"Folder_2\"].astype(\"int\")\n",
    "\n",
    "speakers_info[\"ID\"] = speakers_info[\"ID\"].astype(\"int\")\n",
    "\n",
    "df_speakers_list = df_list_files[[\"Folder_2\",\"Folder_3\",\"Folder_4\", \"Full_Path\"]].merge(\n",
    "    speakers_info[speakers_info[\"SUBSET\"] == \"dev-clean\"], left_on = \"Folder_2\", right_on=\"ID\")\n",
    "df_speakers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ced7ad-faa3-4dd9-b489-6f3c4c17ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_vad_times(audio_signal, threshold_db=-40):\n",
    "    # Convertir la amplitud de la señal a decibelios\n",
    "    amplitude = np.abs(audio_signal)\n",
    "    amplitude_db = 20 * np.log10(amplitude + 1e-6)  # Añadir una pequeña constante para evitar log10(0)\n",
    "    \n",
    "    # Aplicar umbral para obtener una máscara booleana\n",
    "    vad_mask = amplitude_db > threshold_db\n",
    "    \n",
    "    # Detectar los cambios de estado en la máscara booleana\n",
    "    vad_changes = np.diff(vad_mask.astype(int))\n",
    "    \n",
    "    # Encontrar los índices donde ocurre un cambio de 1 (inicio de voz)\n",
    "    vad_start_indices = np.where(vad_changes == 1)[0] + 1  # Añadir 1 para corregir el cambio de índice\n",
    "    \n",
    "    return vad_start_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cde078ee-546b-4adb-9d07-fbc67a3dd63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for index, row in df_speakers_list.iterrows():\n",
    "    file_path = row['Full_Path']\n",
    "    audio_signal, sr = sf.read(file_path)\n",
    "    # Detectar los segundos de actividad de voz\n",
    "    vad_times = detect_vad_times(audio_signal)\n",
    "\n",
    "    # Agregar los resultados a la lista\n",
    "    results.append({'File_Path': file_path, 'VAD_Times': vad_times})\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "vad_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2373118-fdbb-495c-b4bc-e62188f60def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder_2</th>\n",
       "      <th>Folder_3</th>\n",
       "      <th>Folder_4</th>\n",
       "      <th>Full_Path</th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SECONDS</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>VAD_Times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0010.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>[6593, 6596, 6602, 6607, 6610, 6642, 6646, 664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0011.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>[195, 204, 221, 233, 240, 245, 251, 257, 274, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0008.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>[4048, 4051, 4252, 4255, 4486, 4533, 4540, 454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0012.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>[4535, 4540, 5494, 5501, 5528, 5531, 5539, 554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8842</td>\n",
       "      <td>302196</td>\n",
       "      <td>8842-302196-0009.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "      <td>486.0</td>\n",
       "      <td>LibriSpeech/dev-clean/8842/302196/8842-302196-...</td>\n",
       "      <td>[245, 261, 270, 277, 283, 286, 292, 301, 307, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0031.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>[1, 7, 22, 130, 138, 146, 155, 166, 171, 180, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0006.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>[843, 925, 927, 930, 934, 937, 941, 1007, 1012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0017.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>[236, 310, 681, 689, 691, 700, 809, 817, 824, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0032.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>[62, 66, 69, 83, 87, 90, 121, 130, 133, 137, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>2078</td>\n",
       "      <td>142845</td>\n",
       "      <td>2078-142845-0049.flac</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "      <td>481.8</td>\n",
       "      <td>LibriSpeech/dev-clean/2078/142845/2078-142845-...</td>\n",
       "      <td>[158, 161, 181, 188, 192, 196, 199, 206, 224, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2703 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Folder_2  Folder_3               Folder_4  \\\n",
       "0         8842    302196  8842-302196-0010.flac   \n",
       "1         8842    302196  8842-302196-0011.flac   \n",
       "2         8842    302196  8842-302196-0008.flac   \n",
       "3         8842    302196  8842-302196-0012.flac   \n",
       "4         8842    302196  8842-302196-0009.flac   \n",
       "...        ...       ...                    ...   \n",
       "2698      2078    142845  2078-142845-0031.flac   \n",
       "2699      2078    142845  2078-142845-0006.flac   \n",
       "2700      2078    142845  2078-142845-0017.flac   \n",
       "2701      2078    142845  2078-142845-0032.flac   \n",
       "2702      2078    142845  2078-142845-0049.flac   \n",
       "\n",
       "                                              Full_Path    ID SEX     SUBSET  \\\n",
       "0     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "1     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "2     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "3     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "4     LibriSpeech/dev-clean/8842/302196/8842-302196-...  8842   F  dev-clean   \n",
       "...                                                 ...   ...  ..        ...   \n",
       "2698  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2699  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2700  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2701  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "2702  LibriSpeech/dev-clean/2078/142845/2078-142845-...  2078   M  dev-clean   \n",
       "\n",
       "      MINUTES         NAME  SECONDS  \\\n",
       "0        8.10       Mary J    486.0   \n",
       "1        8.10       Mary J    486.0   \n",
       "2        8.10       Mary J    486.0   \n",
       "3        8.10       Mary J    486.0   \n",
       "4        8.10       Mary J    486.0   \n",
       "...       ...          ...      ...   \n",
       "2698     8.03  Kathy Caver    481.8   \n",
       "2699     8.03  Kathy Caver    481.8   \n",
       "2700     8.03  Kathy Caver    481.8   \n",
       "2701     8.03  Kathy Caver    481.8   \n",
       "2702     8.03  Kathy Caver    481.8   \n",
       "\n",
       "                                              File_Path  \\\n",
       "0     LibriSpeech/dev-clean/8842/302196/8842-302196-...   \n",
       "1     LibriSpeech/dev-clean/8842/302196/8842-302196-...   \n",
       "2     LibriSpeech/dev-clean/8842/302196/8842-302196-...   \n",
       "3     LibriSpeech/dev-clean/8842/302196/8842-302196-...   \n",
       "4     LibriSpeech/dev-clean/8842/302196/8842-302196-...   \n",
       "...                                                 ...   \n",
       "2698  LibriSpeech/dev-clean/2078/142845/2078-142845-...   \n",
       "2699  LibriSpeech/dev-clean/2078/142845/2078-142845-...   \n",
       "2700  LibriSpeech/dev-clean/2078/142845/2078-142845-...   \n",
       "2701  LibriSpeech/dev-clean/2078/142845/2078-142845-...   \n",
       "2702  LibriSpeech/dev-clean/2078/142845/2078-142845-...   \n",
       "\n",
       "                                              VAD_Times  \n",
       "0     [6593, 6596, 6602, 6607, 6610, 6642, 6646, 664...  \n",
       "1     [195, 204, 221, 233, 240, 245, 251, 257, 274, ...  \n",
       "2     [4048, 4051, 4252, 4255, 4486, 4533, 4540, 454...  \n",
       "3     [4535, 4540, 5494, 5501, 5528, 5531, 5539, 554...  \n",
       "4     [245, 261, 270, 277, 283, 286, 292, 301, 307, ...  \n",
       "...                                                 ...  \n",
       "2698  [1, 7, 22, 130, 138, 146, 155, 166, 171, 180, ...  \n",
       "2699  [843, 925, 927, 930, 934, 937, 941, 1007, 1012...  \n",
       "2700  [236, 310, 681, 689, 691, 700, 809, 817, 824, ...  \n",
       "2701  [62, 66, 69, 83, 87, 90, 121, 130, 133, 137, 1...  \n",
       "2702  [158, 161, 181, 188, 192, 196, 199, 206, 224, ...  \n",
       "\n",
       "[2703 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speakers_list_vad = df_speakers_list.merge(vad_results, right_on = \"File_Path\", left_on=\"Full_Path\")\n",
    "df_speakers_list_vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb80d03b-3fd3-4546-b5ed-e37035f6d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "def get_audio_segment(audio_signal, start_time, segment_duration_sr):\n",
    "    end_index = start_time + segment_duration_sr\n",
    "    segment = audio_signal[start_time:end_index]\n",
    "    return segment\n",
    "\n",
    "def select_random_valid_vad(vad_times, max_start_time, segment_duration_sr):\n",
    "    \n",
    "    valid_vad_times = [time for time in vad_times if (time) + (segment_duration_sr) <= max_start_time]\n",
    "    return random.choice(valid_vad_times) if valid_vad_times else None\n",
    "\n",
    "def create_segments(df, output_dir,segment_duration, iterations = 10000):\n",
    "    def wrapper(identifier):\n",
    "        num_rows = len(df)\n",
    "        index = 0\n",
    "        x =  0\n",
    "        while x < iterations:\n",
    "            #print(x)\n",
    "            row = df.iloc[index]\n",
    "            file_path = row['File_Path']\n",
    "            vad_times = row['VAD_Times']\n",
    "            \n",
    "            audio_signal, sr = sf.read(file_path, always_2d=False)\n",
    "            start_time = select_random_valid_vad(vad_times, len(audio_signal), segment_duration * sr)\n",
    "            \n",
    "            if start_time is not None:\n",
    "                segment = get_audio_segment(audio_signal, start_time, segment_duration * sr)\n",
    "                sf.write(\"{}/{}_{}.wav\".format(output_dir,identifier,x),segment,sr)\n",
    "                x+=1\n",
    "                #pbar.update(1)\n",
    "            else:\n",
    "                print(\"No valid VAD time\")\n",
    "            index = (index + 1) if index + 1 < num_rows else 0\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9773e322-886a-4e6e-823e-e5ac7965c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08c6a951-7d4f-4f12-a54c-9c27cfd0bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_ids = speakers_info[\"ID\"].unique()\n",
    "train_ids, test_ids = train_test_split(speakers_ids, test_size=0.2, random_state=21)\n",
    "train_df = df_speakers_list_vad[df_speakers_list_vad[\"ID\"].isin(train_ids)]\n",
    "test_df = df_speakers_list_vad[df_speakers_list_vad[\"ID\"].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbbf49a4-bb7c-4408-abe7-79a2a8ad1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aab1401-8f25-4827-b4e4-a381939fd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 1\n",
    "\n",
    "iterations_train = 8000\n",
    "repetitions_train = 10\n",
    "output_train = \"Dataset/speech/train\"\n",
    "\n",
    "iterations_test = 2000\n",
    "repetitions_test = 10\n",
    "output_test = \"Dataset/speech/test\"\n",
    "\n",
    "\n",
    "check_directory(output_train)\n",
    "check_directory(output_test)\n",
    "\n",
    "speech_urls = np.array(find_files_with_extensions(\"Dataset/speech\",[\"*.wav\",\"*.flac\"]))\n",
    "\n",
    "if len(speech_urls) == 0:\n",
    "    with ThreadPool(repetitions_train) as pool:\n",
    "        pool.map(create_segments(train_df, output_train, segment_duration, iterations_train), range(repetitions_train))\n",
    "\n",
    "    with ThreadPool(repetitions_test) as pool:\n",
    "        pool.map(create_segments(test_df, output_test, segment_duration, iterations_test), range(repetitions_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2525539b-064e-44cd-97a5-965befbcda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list_noises = list(find_files_with_extensions(\"musan/noise/free-sound/\",[\"*.wav\",\"*.flac\"]))\n",
    "df_noises = ls_to_df(files_list_noises)\n",
    "df_train_noises, df_test_noises = train_test_split(df_noises, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5eac5ce-bb36-4d91-b1b9-4493d63556e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_audio_segment(audio_signal, segment_duration_sr):\n",
    "    max_start_index = len(audio_signal) - segment_duration_sr\n",
    "    start_index = random.randint(0, max_start_index)\n",
    "    end_index = start_index + segment_duration_sr\n",
    "    segment = audio_signal[start_index:end_index]\n",
    "    return segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3c7c76-1f3a-4f26-8455-dff03881f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 1\n",
    "\n",
    "\n",
    "output_noise_train = \"Dataset/noise/train\"\n",
    "iterations_noise_train = 8000\n",
    "repetitions_noise_train = 10\n",
    "\n",
    "\n",
    "output_noise_test = \"Dataset/noise/test\"\n",
    "iterations_noise_test = 2000\n",
    "repetitions_noise_test = 10\n",
    "\n",
    "check_directory(output_noise_train)\n",
    "check_directory(output_noise_test)\n",
    "\n",
    "\n",
    "def create_segment_noise(df, segment_duration, output_folder, iterations = 10000):\n",
    "    def wrapper(identifier):\n",
    "        num_rows = len(df)\n",
    "        index = 0\n",
    "        x = 0\n",
    "        while x < iterations:\n",
    "            row = df.iloc[index]\n",
    "            file_path = row['Full_Path']\n",
    "            audio_signal, sr = sf.read(file_path, always_2d=False)\n",
    "            if len(audio_signal) > segment_duration * sr:\n",
    "                segment = get_random_audio_segment(audio_signal, segment_duration * sr)\n",
    "                sf.write(\"{}/{}_{}.wav\".format(output_folder,identifier,x),segment,sr)\n",
    "                x+=1\n",
    "            index = (index + 1) if index + 1 < num_rows else 0\n",
    "    return wrapper\n",
    "\n",
    "noise_urls = np.array(find_files_with_extensions(\"Dataset/noise\",[\"*.wav\",\"*.flac\"]))\n",
    "\n",
    "if len(noise_urls) == 0:\n",
    "    with ThreadPool(repetitions_noise_train) as pool:\n",
    "        pool.map(create_segment_noise(df_train_noises, segment_duration, output_noise_train, iterations_noise_train), range(repetitions_noise_train))\n",
    "\n",
    "    with ThreadPool(repetitions_noise_test) as pool:\n",
    "        pool.map(create_segment_noise(df_test_noises, segment_duration, output_noise_test, iterations_noise_test), range(repetitions_noise_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3809d92e-aa7f-462f-ad1c-4adb93d64887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ,fnmatch\n",
    "import math\n",
    "def create_data_from_dir(speech_dir, noise_dir, n_samples):\n",
    "    speech_urls = np.array(random.choices(find_files_with_extensions(speech_dir,[\"*.wav\",\"*.flac\"]), k = n_samples))\n",
    "    noise_urls = np.array(random.choices(find_files_with_extensions(noise_dir,[\"*.wav\",\"*.flac\"]), k = n_samples))\n",
    "    return np.array(list(zip(speech_urls,noise_urls)))\n",
    "\n",
    "\n",
    "mix_urls_train = create_data_from_dir(\"Dataset/speech/train\",\n",
    "                                     \"Dataset/noise/train\", 100000)\n",
    "\n",
    "mix_urls_valid = create_data_from_dir(\"Dataset/speech/test\",\n",
    "                                     \"Dataset/noise/test\", 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6939738-b4f4-41e0-9859-0bcb17e2e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 18:23:48.730726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-05 18:23:49.523731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.metrics import *\n",
    "import tensorflow as tf\n",
    "\n",
    "# https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs\n",
    "def generic_model(timesteps,len_inputs,hidden,layers,cell,n_fc,fc_size,resnet,use_relu,batch_norm):\n",
    "    inputs = Input(shape=[timesteps,len_inputs,1])\n",
    "    x = Reshape([timesteps, len_inputs])(inputs)\n",
    "    if use_relu:\n",
    "        x = ReLU()(x)\n",
    "\n",
    "    rnn = LSTM(hidden,return_sequences=True) if cell == \"LSTM\" else Bidirectional(LSTM(hidden,return_sequences=True))\n",
    "    x = rnn(x)\n",
    "    \n",
    "    if use_relu:\n",
    "        x = ReLU()(x)\n",
    "\n",
    "    for i in range(layers - 1):\n",
    "        rnn = LSTM(hidden,return_sequences=True) if cell == \"LSTM\" else Bidirectional(LSTM(hidden,return_sequences=True))\n",
    "        r = rnn(x)\n",
    "        \n",
    "        if use_relu:\n",
    "            x  =ReLU()(x)\n",
    "\n",
    "        x = Add()([r,x]) if resnet else r\n",
    "\n",
    "        ### si es la penultima \n",
    "        if batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    x = Flatten()(x)\n",
    "    for i in range(n_fc):\n",
    "        x = Dense(fc_size, activation='relu')(x)\n",
    "\n",
    "    x = Dense(timesteps * len_inputs * 2, activation=None)(x)\n",
    "\n",
    "    x = Reshape([timesteps,len_inputs,2])(x)\n",
    "    x = Softmax(axis=-1)(x)\n",
    "    #x = Concatenate(axis=-1)([x, x, x, x, x])\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d2ba7dd-8a40-433c-aa30-4341b85d090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from signaltransform import *\n",
    "\n",
    "def prepare_signals(v,n,fac1,fac2):\n",
    "    v = 1 / np.abs(v).max() * v\n",
    "    n = 1 / np.abs(n).max() * n\n",
    "    v = v * float(fac1) \n",
    "    n = n * float(fac2) \n",
    "    return v, n\n",
    "\n",
    "def feature_extractor0(input_feature, audio_len, apply_vad, vad_threshold, nperseg = 512, noverlap = 256):\n",
    "    def extract_features(data):\n",
    "        speech, noise= data\n",
    "        v,_ = sf.read(speech)\n",
    "        n,_ = sf.read(noise)\n",
    "\n",
    "        v = v[:audio_len]\n",
    "        n = n[:audio_len]\n",
    "\n",
    "        v, n = prepare_signals(v, n,  random.uniform(.8, 1), random.uniform(.8, 1))\n",
    "        mix = (v + n) / 2.0\n",
    "\n",
    "        _, _, complex_v = signal.stft(v, fs=16000, nperseg=nperseg, noverlap=noverlap)\n",
    "        _, _, complex_n = signal.stft(n, fs=16000, nperseg=nperseg, noverlap=noverlap)\n",
    "        _, _, complex_mix = signal.stft(mix, fs=16000, nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "        mag_v = np.abs(complex_v)\n",
    "        mag_n = np.abs(complex_n)\n",
    "        mag_mix = np.abs(complex_mix)\n",
    "        angles_mix = np.angle(complex_mix)\n",
    "        mag_mix_db = db(mag_mix,10000.,10000.)\n",
    "\n",
    "        if input_feature == \"mag\":\n",
    "            x = reduce_standarize_mag(mag_mix)\n",
    "        elif input_feature == \"mag_db\":\n",
    "            x = reduce_standarize(mag_mix_db)\n",
    "\n",
    "        VAD = vad(mag_mix_db, vad_threshold)\n",
    "        \n",
    "        if not apply_vad:\n",
    "            VAD_t = np.ones_like(VAD)\n",
    "\n",
    "\n",
    "        y = np.array((mag_v > mag_n)).astype(np.float32)\n",
    "\n",
    "        y_t_c = np.stack([np.transpose(y,[1,0]),np.transpose(1 - y,[1,0]),np.transpose(VAD,[1,0]),np.transpose(x,[1,0]),np.transpose(mag_mix,[1,0]),np.transpose(angles_mix,[1,0])])\n",
    "        \n",
    "        return  np.transpose(x,[1,0])[...,np.newaxis],np.transpose(y_t_c,[1,2,0])\n",
    "\n",
    "    return extract_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7d3be75-e0ab-441d-8197-a20a4543fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = feature_extractor0(\"mag_db\", 16384, True, 40.0, 512, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e85d473-4da6-4e05-b745-c3ebd18314aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = feature_extractor(mix_urls_train[0])\n",
    "timesteps = x.shape[0]\n",
    "len_inputs =  x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1387edb3-483d-48ba-83d2-34ffa1661eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 18:23:54.444361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.524907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.525121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.526531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.526737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.526916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.608115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.608268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.608381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-05 18:23:54.608468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6095 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = generic_model(timesteps ,len_inputs, 160,6 ,\"BLSTM\" ,2 ,128 , True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c879135-3024-4673-906d-f03c19b240b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from losses import *\n",
    "from metrics2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d4aa11f-1d29-4903-a26c-f43815bd3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import BinaryAccuracy as BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9bc0b12-19f3-4a07-846c-2c7446f3c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSE\n",
    "metric = binary_accuracy_c\n",
    "optimizer  = Adam(1e-3)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= optimizer,\n",
    "    loss= loss,\n",
    "    metrics= [metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "167ce6e6-bbd4-4a14-9cad-4797276c6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class XYGenerator(Sequence):\n",
    "    def __init__(self, ids, batch_size, data,feature_extractor):\n",
    "        'Initialization'\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #carga de batches\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(index * self.batch_size, (index + 1) * self.batch_size):\n",
    "            x, y = self.feature_extractor(self.data[i])\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        return np.array(X),np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ec84fcd-d7b9-4e6f-a2a3-9361e4abc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 50\n",
    "total_items = len(mix_urls_train)\n",
    "num_batches = int(total_items/batch_size)\n",
    "\n",
    "training_generator = XYGenerator(range(num_batches), batch_size, mix_urls_train, feature_extractor)\n",
    "\n",
    "valid_total_items = len(mix_urls_valid)\n",
    "valid_batch_size = batch_size\n",
    "valid_num_batches = int(valid_total_items/valid_batch_size)\n",
    "\n",
    "test_generator = XYGenerator(range(valid_num_batches),valid_batch_size,mix_urls_valid,feature_extractor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddebc259-d2f7-4177-a412-015a0bfc092c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 17:12:16.659831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-09-05 17:12:16.917089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x76ba5c03e9a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-05 17:12:16.917127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2024-09-05 17:12:16.931241: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-05 17:12:17.089549: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 565s 277ms/step - loss: 0.4505 - binary_accuracy_c: 0.9067 - val_loss: 0.4357 - val_binary_accuracy_c: 0.9182\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 541s 271ms/step - loss: 0.3882 - binary_accuracy_c: 0.9220 - val_loss: 0.4162 - val_binary_accuracy_c: 0.9201\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 543s 271ms/step - loss: 0.3750 - binary_accuracy_c: 0.9249 - val_loss: 0.4088 - val_binary_accuracy_c: 0.9199\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 535s 268ms/step - loss: 0.3699 - binary_accuracy_c: 0.9260 - val_loss: 0.4146 - val_binary_accuracy_c: 0.9184\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 537s 269ms/step - loss: 0.3668 - binary_accuracy_c: 0.9267 - val_loss: 0.4024 - val_binary_accuracy_c: 0.9224\n",
      "Epoch 6/50\n",
      "1293/2000 [==================>...........] - ETA: 1:39 - loss: 0.3645 - binary_accuracy_c: 0.9274"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(training_generator, validation_data= test_generator, epochs= epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83c8c2e6-a150-4de4-9508-af5fde51fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions(predicted,x_list,y_list, nperseg = 512, noverlap = 256):\n",
    "    i = 0\n",
    "    for predicted_, x , y in zip(predicted,x_list,y_list):\n",
    "        print(y.shape)\n",
    "        mag_mix = y[...,4:5]\n",
    "        angles_mix = y[...,5:6]\n",
    "        complex_mix = mag_mix * np.exp(angles_mix*1j)\n",
    "        print(complex_mix.shape)\n",
    "        print(type(complex_mix))\n",
    "        #exit(0)\n",
    "        print(predicted_.shape)\n",
    "        print(complex_mix.shape)\n",
    "        _, source_recovered_a = signal.istft(np.transpose(predicted_[...,0],[1,0]) * np.transpose(complex_mix[...,0],[1,0]) , fs=16000 ,nperseg= nperseg, noverlap = noverlap)\n",
    "        _, source_recovered_b = signal.istft(np.transpose(1 - predicted_[...,0],[1,0]) * np.transpose(complex_mix[...,0],[1,0]) , fs=16000 ,nperseg= nperseg, noverlap = noverlap)\n",
    "        _, source_recovered_x = signal.istft(np.transpose(complex_mix[...,0],[1,0]) , fs=16000 ,nperseg= nperseg, noverlap = noverlap)\n",
    "        sf.write(\"{}_a.wav\".format(i),source_recovered_a,16000)\n",
    "        sf.write(\"{}_b.wav\".format(i),source_recovered_b,16000)\n",
    "        sf.write(\"{}_x.wav\".format(i),source_recovered_x,16000)\n",
    "        i+=1\n",
    "\n",
    "def create_predictions_pred(predicted,x_list,pred_folder, nperseg, noverlap):\n",
    "    i = 0\n",
    "    for predicted_list, complex_list  in zip(predicted,x_list):\n",
    "        recovered_a = []\n",
    "        recovered_b = []\n",
    "        recovered_x = []\n",
    "        for predicted_, complex_mix in zip(predicted_list,complex_list):\n",
    "            _, source_recovered_a = signal.istft(np.transpose(predicted_[...,0],[1,0]) * np.transpose(complex_mix[...,0],[1,0]) , fs=16000 ,nperseg= nperseg, noverlap = noverlap)\n",
    "            _, source_recovered_b = signal.istft(np.transpose(1 - predicted_[...,0],[1,0]) * np.transpose(complex_mix[...,0],[1,0]) , fs=16000 ,nperseg= nperseg, noverlap = noverlap)\n",
    "            _, source_recovered_x = signal.istft(np.transpose(complex_mix[...,0],[1,0]) , fs=16000 ,nperseg= nperseg, noverlap = noverlap)\n",
    "            recovered_a.append(source_recovered_a)\n",
    "            recovered_b.append(source_recovered_b)\n",
    "            recovered_x.append(source_recovered_x)\n",
    "\n",
    "        sf.write(\"{}/{}_a.wav\".format(pred_folder,i),np.array(recovered_a).reshape(-1),16000)\n",
    "        sf.write(\"{}/{}_b.wav\".format(pred_folder,i),np.array(recovered_b).reshape(-1),16000)\n",
    "        sf.write(\"{}/{}_x.wav\".format(pred_folder,i),np.array(recovered_x).reshape(-1),16000)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "179abeb2-ac8e-4aaf-ac63-89557738d821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n",
      "(64, 257, 6)\n",
      "(64, 257, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 257, 2)\n",
      "(64, 257, 1)\n"
     ]
    }
   ],
   "source": [
    "pred_batch_size = 15\n",
    "pred_total_items = 15 \n",
    "pred_num_batches = int((pred_total_items/pred_batch_size))\n",
    "predGen = XYGenerator(range(pred_num_batches),pred_batch_size,mix_urls_valid[0:15],feature_extractor) # Change the 3 to range(x+1) where x is the number of npy files you want to train on\n",
    "predicted = model.predict(predGen)\n",
    "pred_gen = [[x,y] for x,y in predGen]\n",
    "\n",
    "create_predictions(predicted,pred_gen[0][0],pred_gen[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29bd538-54f6-4564-9c92-cf21d17b27a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27da1f-eb96-4163-8833-800a8770e577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
